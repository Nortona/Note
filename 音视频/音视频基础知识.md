


# 比特率
显示一段视频每秒所需的比特数量就是它的**比特率**。
> 比特率 = 宽 * 高 * 比特深度 * 帧每秒

例如，一段每秒30帧，每像素24比特，分辨率是480x240的视频，如果我们不做任何压缩，它将需要 **82,944,000 比特每秒**或 82.944 Mbps (30x480x240x24)。



# 视频压缩

使用一个视频而不做任何压缩是不可行的；**一个单独的一小时长的视频**，分辨率为720p和30fps时将**需要 278GB***。由于**仅使用独自无损数据压缩算法**，如 DEFLATE（被PKZIP, Gzip, 和 PNG 使用），**不会**足够减少所需的带宽，我们需要找到其它压缩视频的方法。
 >我们使用乘积得出这个数字 1280 x 720 x 24 x 30 x 3600 （宽，高，每像素比特数，fps 和秒数）

## 三角帧技术

==帧类型：I P B==
这是最开始的 4 帧。
![[Pasted image 20230504224739.png]]

以在帧内看到**很多重复内容**，如**蓝色背景**，从 0 帧到第 3 帧它都没有变化。为了解决这个问题，我们可以将它们**抽象地分类**为三种类型的帧。
#### **I 帧（帧内编码，关键帧）**

I 帧（可参考，关键帧，帧内编码）是一个**自足的帧**。它不依靠任何东西来渲染，I 帧与静态图片相似。第一帧通常是 I 帧，但我们将看到 I 帧被定期插入其它类型的帧之间。

#### **P 帧（预测）**
![[Pasted image 20230504224942.png]]

P 帧利用了一个事实：当前的画面几乎总能**使用之前的一帧进行渲染**。例如，在第二帧，唯一的改变是球向前移动了。仅仅使用（第二帧）对前一帧的引用和差值，我们就能重建前一帧。

#### **B 帧（双向预测）**

如何引用前面和后面的帧去做更好的压缩？！简单地说 B 帧就是这么做的。
![[Pasted image 20230504225129.png]]


 I 帧是昂贵的，P 帧是便宜的，最便宜的是 B 帧。
 ![[Pasted image 20230504225059.png]]



## 时间冗余（帧间预测）
包括==运动估计==和==运动补偿==

1. 简单地**从帧 0 里减去帧 1**，就可以得到刚好需要我们**去编码的剩余值**。
![[Pasted image 20230505131900.png]]
![[Pasted image 20230505131904.png]]

2. 块运动补偿
**块运动补偿**是将当前帧划分为非重叠的块，并且运动补偿向量**告诉这些块来自哪里**
![[Pasted image 20230505132052.png]]

预计那个球会从 `x=0, y=25` 移动到 `x=6, y=26`，**x** 和 **y** 的值就是**运动向量**。我们**下一步**可以通过只对在最终块的位置和预期值之间的**运动向量差进行编码**来节省比特，那么最终运动向量就是 `x=6 (6-0), y=1 (26-25)`。

运用**运动预测**时**编码的数据少于**使用简单的三角帧技术。（ 三角帧：在视频压缩技术里，P 帧或 B 帧的别名。）



## 空间冗余（帧内预测）
如果我们分析一个视频里的**每一帧**，我们会看到有**许多区域是相互关联的**。
![[Pasted image 20230505134351.png]]

这是一个 `I 帧`，并且我们**不能使用前面的帧来预测**，但仍然可以压缩它。我们将编码选择的红色块。如果我们**看看它的周围**，我们可以**估计它周围颜色的趋势**。
![[Pasted image 20230505134506.png]]

**预计**帧将继续**垂直传播（它的）颜色**，这意味着**未知像素的颜色将保持其邻居的值**。
![[Pasted image 20230505135028.png]]


我们的**预计也会错**，所以我们需要应用这项技术（**帧间预测**），然后**减去给我们的残差块的值**，得出一个相比原始数据可压缩的矩阵。
![[Pasted image 20230505134458.png]]


ffmpeg查看运动预测
```shell
ffmpeg -flags2 +export_mvs -i mv.mp4 -vf codecview=mv=pf+bf+bb mv_vis_mv.mp4
```



## 编码规范
10秒钟1080p（1920x1080）、30fps的YUV420P原始视频，需要占用多大的存储空间？
- (10 * 30) * (1920 * 1080) * 1.5 = 933120000字节 ≈ 889.89MB

需要先使用视频编码技术（比如H.264编码）对原始视频进行压缩，然后再进行存储和分发。H.264编码的压缩比可以达到至少是100:1。
### H.264编码
H.264，又称为**MPEG-4 Part 10，Advanced Video Coding**。

- 译为：**MPEG-4第10部分，高级视频编码**
- 简称：**MPEG-4 AVC**

基本的视频压缩原则：
1. 用于降低空间相关的变
2. 控制比特率的量化
3. 降低时间相关的运动补偿预测
4. 降低统计相关的熵编码、

新的和改进的方法罗列如下
1. 自适应帧内预测；
2. 整数精度的小尺寸块变换；
3. 多参考帧和广义B 帧；
4. 可变的块大小；
5. 1/4像素精度的运动补
6. 内容自适应环路去块效应滤波器；
7. 引入CABAC（上下文自适应二进制算术编码）和CAVLC（上下文自适应变长编码）改善的熵编码
#### H· 264 的档次
档次定义为一个编码工具的子集
H· 264 所定义的档次如下所列：
1） 基本档次；
2） 扩展档次；
3） 主档次；
4） 高档次（定义在FRExts 修正案中）
![[Pasted image 20230701170327.png]]


![[Pasted image 20230701165949.png]]

![[Pasted image 20230701170626.png]]
H· 264 编码器框图

#### 编码过程与原理
大体可以归纳为以下几个主要步骤：

- 划分帧类型
- 帧内/帧间编码
- 变换 + 量化
- 滤波
- 熵编码


##### 划分帧类型
在连续的几帧图像中，一般只有10%以内的像素有差别，亮度的差值变化不超过2%，而色度的差值变化只在1%以内。

###### GOP
将一串连续的相似的帧归到一个图像群组（Group Of Pictures，**GOP**）。
![[Pasted image 20230630164417.png]]

GOP中的帧可以分为3种类型：

- **I**帧（I Picture、I Frame、Intra Coded Picture），译为：**帧内编码图像**，也叫做关键帧（Keyframe）
    - 是视频的第一帧，也是GOP的第一帧，一个GOP只有一个I帧
    - 编码
        - 对整帧图像数据进行编码
    - 解码
        - 仅用当前I帧的编码数据就可以解码出完整的图像
    - 是一种自带全部信息的独立帧，无需参考其他图像便可独立进行解码，可以简单理解为一张静态图像
- **P**帧（P Picture、P Frame、Predictive Coded Picture），译为：**预测编码图像**
    - 编码
        - 并不会对整帧图像数据进行编码
        - 以前面的I帧或P帧作为参考帧，只编码当前P帧与参考帧的差异数据
    - 解码
        - 需要先解码出前面的参考帧，再结合差异数据解码出当前P帧完整的图像
- **B**帧（B Picture、B Frame、Bipredictive Coded Picture），译为：**前后预测编码图像**
    - 编码
        - 并不会对整帧图像数据进行编码
        - 同时以前面、后面的I帧或P帧作为参考帧，只编码当前B帧与前后参考帧的差异数据
        - 因为可参考的帧变多了，所以只需要存储更少的差异数据
    - 解码
        - 需要先解码出前后的参考帧，再结合差异数据解码出当前B帧完整的图像

不难看出，编码后的数据大小：I帧 > P帧 > B帧。
![[Pasted image 20230630164601.png]]

在较早的视频编码标准（例如MPEG-2）中，P帧只能使用一个参考帧，而一些现代视频编码标准（比如H.264），允许使用多个参考帧。
![[Pasted image 20230630164640.jpg]]



##### 帧内/帧间编码
- I帧采用的是帧内（Intra Frame）编码，处理的是空间冗余。  
- P帧、B帧采用的是帧间（Inter Frame）编码，处理的是时间冗余。

###### 划分宏块
在进行编码之前，首先要将一张完整的帧切割成多个宏块（Macroblock），H.264中的宏块大小通常是16x16。

宏块可以进一步拆分为多个更小的变换块（Transform blocks）、预测块（Prediction blocks）。

- 变换块的尺寸有：16x16、8x8、4x4
    
- 预测块的尺寸有：16×16、16×8、8×16、8×8、8×4、4×8、4×4





# 颜色编码方式
## YUV
YUV数据由Y、U、V三个分量组成，现在通常说的YUV指的是**YCbCr**。
- **Y**：表示亮度（Luminance、Luma），占8bit（1字节）
- **Cb**、**Cr**：表示色度（Chrominance、Chroma）
    - **Cb**（U）：蓝色色度分量，占8bit（1字节）
    - **Cr**（V）：红色色度分量，占8bit（1字节）

### 转换公式
```
公式1：
- RGB的取值范围是[0,255]
- Y的取值范围是[16,235]
- UV的取值范围是[16,239]

Y = 0.257R + 0.504G + 0.098B + 16
U = -0.148R - 0.291G + 0.439B + 128
V = 0.439R - 0.368G - 0.071B + 128
 
R = 1.164(Y - 16) + 2.018(U - 128)
G = 1.164(Y - 16) - 0.813(V - 128) - 0.391(U - 128)
B = 1.164(Y - 16) + 1.596(V - 128)
```

```
公式2：
- RGB的取值范围是[0, 1]
- Y的取值范围是[0, 1]
- UV的取值范围是[-0.5, 0.5]

Y = 0.299R + 0.587G + 0.114B
U = 0.564(B - Y) = -0.169R - 0.331G + 0.500B
V = 0.713(R - Y) = 0.500R - 0.419G - 0.081B
 
R = Y + 1.403V
G = Y - 0.344U - 0.714V
B = Y + 1.770U
```

```
公式3：
- RGB的取值范围是[0, 255]
- YUV的取值范围是[0, 255]

Y = 0.299R + 0.587G + 0.114B
U = -0.169R - 0.331G + 0.500B + 128
V = 0.500R - 0.419G - 0.081B + 128
 
R = Y + 1.403(V - 128)
G = Y - 0.343(U - 128) - 0.714(V - 128)
B = Y + 1.770(U - 128)
```

### 色度二次采样
如果在色度分量上进行（相对亮度分量）较低分辨率的采样，也就是存储较多的亮度细节、较少的色度细节，这样就可以在不明显降低画面质量的同时减小图像的体积。上述过程称为：**色度二次采样**（Chroma Subsampling）。

#### 采样格式
采样格式通常用A:B:C的形式来表示，比如4:4:4、4:2:2、4:2:0等，其中我们最需要关注的是**4:2:0**。

比例N1∶ N2∶ N3 里面的数字指水平方向上的相对采样率， N1 表示在奇数行和偶数行里Y 样本的个数， N2 表示奇数行里Cb 和Cr 样本的个数， N3 是偶数行里Cb 和Cr 样本的个数

- **A**：一块A*2个像素的概念区域，一般都是4
- **B**：第1行的色度采样数目
- **C**：第2行的色度采样数目
    - C的值一般要么等于B，要么等于0
![[Pasted image 20230628195133.png]]
![[Pasted image 20230628195142.png]]

上图中，不管是哪种采样格式，Y分量都是全水平、全垂直分辨率采样的，每一个像素都有自己独立的Y分量。

#### 4:4:4
- 第1行采集4组CbCr分量，第2行采集4组CbCr分量
- 每1个像素都有自己独立的1组CbCr分量
    - Y分量与CbCr分量的水平方向比例是1:1（每1列都有1组CbCr分量）
    - Y分量与CbCr分量的垂直方向比例是1:1（每1行都有1组CbCr分量）
    - Y分量与CbCr分量的总比例是1:1
- 1个像素占用24bit（3字节），跟RGB888的体积一样
    - 24bpp（bits per pixel）
- 这种格式是没有进行色度二次采样的
![[497279-20210426104306964-2082053712.gif]]
叉叉代表：亮度。

圆圈代表：色度。


#### 4:2:2
在4∶ 2∶ 2 的采样模式中， 不仅对于奇数行里的每4 个亮度样本有2 个Cb 和Cr 样本， 而且对于偶数行里的每4 个亮度样本也有2 个Cb 和Cr 样本。

- 第1行采集2组CbCr分量，第2行采集2组CbCr分量
- 水平方向相邻的2个像素（1行2列）共用1组CbCr分量
    - Y分量与CbCr分量的水平方向比例是2:1（每2列就有1组CbCr分量）
    - Y分量与CbCr分量的垂直方向比例是1:1（每1行都有1组CbCr分量）
    - Y分量与CbCr分量的总比例是2:1
- 1个像素平均占用16bit（2字节）
    - 16bpp
    - 因为2个像素共占用32bit（4字节 = 2个Y分量 + 1个Cb分量 + 1个Cr分量）
![[497279-20210426104309834-1923088815.gif]]



#### 4:2:0
在4∶ 2∶ 0 的采样模式中， N1 =4， N2 =2， N3 =0。这意味着对于奇数行里的每4 个亮度样本， 有2 个Cb 样本和2 个Cr 样本； 但对于偶数行里的每4 个亮度样本， 没有Cb 和Cr 样本。

- 第1行采集2组CbCr分量，第2行共享第1行的CbCr分量
- 相邻的4个像素（2行2列）共用1组CbCr分量
    - Y分量与CbCr分量的水平方向比例是2:1（每2列就有1组CbCr分量）
    - Y分量与CbCr分量的垂直方向比例是2:1（每2行就有1组CbCr分量）
    - Y分量与CbCr分量的总比例是4:1
- 1个像素平均占用12bit（1.5字节）
    - 12bpp
    - 因为4个像素共占用48bit（6字节 = 4个Y分量 + 1个Cb分量 + 1个Cr分量）
![[497279-20210426104312115-357762309.gif]]
4:2:0 MPEG-1

![[497279-20210426110953281-1335685401.gif]]
4:2:0 MPEG-2

### 存储格式
YUV的存储格式可以分为3大类：
- **Planar**（平面）
    - Y、U、V分量分开单独存储
    - 名称通常以字母p结尾
- **Semi-Planar**（半平面）
    - Y分量单独存储，U、V分量交错存储
    - 名称通常以字母sp结尾
- **Packed**（紧凑）
    - 或者叫**Interleaved** （交错）
    - Y、U、V分量交错存储

![[Pasted image 20230628200818.png]]


```
Planar

1.I444

Y Y Y Y
Y Y Y Y
U U U U
U U U U
V V V V
V V V V

2.YV24

Y Y Y Y
Y Y Y Y
V V V V
V V V V
U U U U
U U U U

Semi-Planar

1.NV24

Y Y Y Y
Y Y Y Y
U V U V U V U V
U V U V U V U V

2.NV42
Y Y Y Y
Y Y Y Y
V U V U V U V U
V U V U V U V U


```

![[Pasted image 20230628201219.png]]

```
Planar
1.I422
Y Y Y Y
Y Y Y Y
U U
U U
V V
V V

2.YV16
Y Y Y Y
Y Y Y Y
V V
V V
U U
U U

Semi-Planar

1.NV16
Y Y Y Y
Y Y Y Y
U V U V
U V U V

2.NV61
Y Y Y Y
Y Y Y Y
V U V U
V U V U


```


## 格式转换
### 其他图片格式转YUV
```shell
ffmpeg -i in.png -s 512x512 -pix_fmt yuv420p out.yuv|
```
上述命令生成的yuv文件大小是：393216字节 = 512 * 512 * 1.5字节。

- _-s_
    - 设置图片的尺寸
    - 可以用一些[固定字符串](https://ffmpeg.org/ffmpeg-all.html#Video-size)表示尺寸，比如**hd720**表示**1280x720**
    - 如果不设置此选项，默认会跟随输入图片的尺寸
- _-pix_fmt_
    - 设置像素格式
    - 可以通过`ffmpeg -pix_fmts`查看FFmpeg支持的像素格式
    - 如果不设置此选项，默认会跟随输入图片的像素格式
        - 比如可能是**rgb24**、**rgba8**、**pal8**等
        - 可以通过_ffprobe_查看某图片的像素格式，比如`ffprobe in.png`


### YUV转其他图片格式
```shell
ffmpeg -s 512x512 -pix_fmt yuv420p -i in.yuv out.jpg|
```
- 这里必须得设置YUV的尺寸（_-s_）、像素格式（_-pix_fmt_）
- 这就类似于：对pcm进行编码时，必须得设置采样率（_-ar_）、声道数（_-ac_）、采样格式（_-f_）

### 显示YUV
```shell
ffplay -video_size 512x512 -pixel_format yuv420p in.yuv

# 只显示r分量
ffplay -vf extractplanes=r in.png
 
# 只显示g分量
ffplay -vf extractplanes=g in.png
 
# 只显示b分量
ffplay -vf extractplanes=b in.png
 
# 只显示y分量
ffplay -video_size 512x512 -pixel_format yuv420p -vf extractplanes=y in.yuv
# 只显示y分量
ffplay -video_size 512x512 -pixel_format yuv420p -vf extractplanes=u in.yuv
# 只显示y分量
ffplay -video_size 512x512 -pixel_format yuv420p -vf extractplanes=v in.yuv

```

# 视频录制
```shell
### dshow支持的设备
ffmpeg -f dshow -list_devices true -i dummy

## 默认参数录制
ffmpeg -f dshow -i video="Integrated Camera" out.yuv
## 自定义参数录制
ffmpeg -f dshow -video_size 640x480 -pixel_format yuyv422 -framerate 30 -i video="Integrated Camera" out.yuv|

## 播放
ffplay -video_size 1280x720 -pixel_format yuvj422p -framerate 30 out.yuv
```




------------------------------ 音频 ---------------------------------


录音的原理可以简单理解为：把声源的振动记录下来，需要时再让某个物体按照记录下来的振动规律去振动，就会产生与原来一样的声音。

# PCM
## 音频数字化
将**模拟信号**（Analog Signal）转成**数字信号**（Digital Signal）后进行存储

![[Pasted image 20230607093803.png]]

## 脉冲编码调制
将音频数字化的常见技术方案是**脉冲编码调制**（**PCM**，Pulse Code Modulation）
主要过程是：**采样 → 量化 → 编码**。
![[Pasted image 20230607093904.png]]

### 采样
模拟信号的波形是无限光滑的，可以看成由无数个点组成，由于存储空间是相对有限的，数字编码过程中，必须要对波形的点进行采样。**采样**（Sampling）：每隔一段时间采集一次模拟信号的样本，是一个在时间上将模拟信号离散化（把连续信号转换成离散信号）的过程。

#### 采样率
每秒采集的样本数量，称为**采样率**（采样频率，采样速率，Sampling Rate）。比如，采样率44.1kHz表示1秒钟采集44100个样本。

#### 采样定理
只有当采样率高于声音信号最高频率的**2**倍时，才能把采集的声音信号唯一地还原成原来的声音。人耳能够感觉到的最高声音频率为20000Hz，因此为了满足人耳的听觉要求，需要至少每秒进行40000次采样（40kHz采样率）。这就是为什么常见的CD的采样率为44.1kHz。电话、无线对讲机、无线麦克风等的采样率是8kHZ。

### 量化
**量化**（Quantization）：将每一个采样点的样本值数字化。

#### 位深度
**位深度**（采样精度，采样大小，Bit Depth）：使用多少个二进制位来存储一个采样点的样本值。位深度越高，表示的振幅越精确。常见的CD采用16bit的位深度，能表示65536（216）个不同的值。DVD使用24bit的位深度，大多数电话设备使用8bit的位深度。
![[Pasted image 20230607094146.png]]

### 编码
**编码**：将采样和量化后的数字数据转成二进制码流。

## PCM数据
采样率44.1kHZ、位深度16bit的1分钟立体声PCM数据有多大？

- 采样率 * 位深度 * 声道数 * 时间
- _44100 * 16 * 2 * 60 / 8 ≈ 10.34MB_

## 比特率
**比特率**（Bit Rate），指单位时间内传输或处理的比特数量，单位是：比特每秒（bit/s或bps），还有：千比特每秒（Kbit/s或Kbps）、兆比特每秒（Mbit/s或Mbps）、吉比特每秒（Gbit/s或Gbps）、太比特每秒（Tbit/s或Tbps）。

采样率44.1kHZ、位深度16bit的立体声PCM数据的比特率是多少？

- 采样率 * 位深度 * 声道数
- _44100 * 16 * 2 = 1411.2Kbps_

# 音频的编码与解码

## 编码
PCM数据可以理解为是：**未经压缩的原始音频数据**，体积比较大，为了更便于存储和传输，一般都会使用某种**音频编码**对它进行编码压缩，然后再存成某种**音频文件格式**。

压缩分为**无损**压缩和**有损**压缩。

- **无损**压缩
    - 解压后**可以**完全还原出原始数据
    - 压缩比**小**，体积**大**
- **有损**压缩
    - 解压后**不能**完全还原出原始数据，会丢失一部分信息
    - 压缩比**大**，体积**小**
    - 压缩比越大，丢失的信息就越多，还原后的信号失真就会越大
    - 一般是通过**舍弃原始数据中对人类听觉不重要的部分**，达成压缩成较小文件的目的
- 压缩比 = 未压缩大小 / 压缩后大小

## 解码
当需要播放音频时，得先解码（解压缩）出PCM数据，然后再进行播放。
![[Pasted image 20230607101343.png]]

# 常见的音频编码和文件格式

需要注意的是：**音频文件格式并不等于音频编码**。比如：

- **WAV**只是一种文件格式，并不是一种编码
    
- **FLAC**既是一种文件格式，又是一种编码

![[Pasted image 20230607101439.png]]


查看录音设备
```shell
ffmpeg -list_devices true -f dshow -i dummy
```

指定录音设备录音
```shell
ffmpeg -f dshow -i audio="耳 机 (EDIFIER W800BT Plus Hands-Free AG Audio)" out.wav
```

## WAV文件格式
- WAV、AVI文件都是基于RIFF标准的文件格式，开头都是RIFF
![[Pasted image 20230616090352.png]]
每一个chunk（数据块）都由3部分组成：
- **id**：chunk的标识
- **data size**：chunk的数据部分大小，字节为单位
- **data**，chunk的数据部分

整个WAV文件是一个RIFF chunk，它的data由3部分组成：

- **format**：文件类型
- **fmt chunk**
    - **音频参数**相关的chunk
    - 它的data里面有采样率、声道数、位深度等参数信息
- **data chunk**
    - **音频数据**相关的chunk
    - 它的data就是真正的音频数据（比如PCM数据）

RIFF chunk除去data chunk的data（音频数据）后，剩下的内容可以称为：WAV文件头，一般是44字节。


### PCM转WAV

#### 命令行
```shell
ffmpeg -ar 44100 -ac 2 -f s16le -i out.pcm out.wav
```
上面命令生成的WAV文件头有78字节。对比44字节的文件头，它多增加了一个34字节大小的LIST chunk。（存放FFmpeg版本等信息）

加上一个输出文件参数_-bitexact_可以去掉LIST Chunk。
```shell
ffmpeg -ar 44100 -ac 2 -f s16le -i out.pcm -bitexact out2.wav|
```

#### 编程
在PCM数据的前面插入一个44字节的WAV文件头，就可以将PCM转成WAV。
```c++
#define AUDIO_FORMAT_PCM 1
#define AUDIO_FORMAT_FLOAT 3
 
// WAV文件头（44字节）
typedef struct {
    // RIFF chunk的id
    uint8_t riffChunkId[4] = {'R', 'I', 'F', 'F'};
    // RIFF chunk的data大小，即文件总长度减去8字节
    uint32_t riffChunkDataSize;
 
    // "WAVE"
    uint8_t format[4] = {'W', 'A', 'V', 'E'};
 
    /* fmt chunk */
    // fmt chunk的id
    uint8_t fmtChunkId[4] = {'f', 'm', 't', ' '};
    // fmt chunk的data大小：存储PCM数据时，是16
    uint32_t fmtChunkDataSize = 16;
    // 音频编码，1表示PCM，3表示Floating Point
    uint16_t audioFormat = AUDIO_FORMAT_PCM;
    // 声道数
    uint16_t numChannels;
    // 采样率
    uint32_t sampleRate;
    // 字节率 = sampleRate * blockAlign
    uint32_t byteRate;
    // 一个样本的字节数 = bitsPerSample * numChannels >> 3
    uint16_t blockAlign;
    // 位深度
    uint16_t bitsPerSample;
 
    /* data chunk */
    // data chunk的id
    uint8_t dataChunkId[4] = {'d', 'a', 't', 'a'};
    // data chunk的data大小：音频数据的总长度，即文件总长度减去文件头的长度(一般是44)
    uint32_t dataChunkDataSize;
} WAVHeader;
```


### 音频重采样
#### 命令行
```shell
ffmpeg -ar 44100 -ac 2 -f s16le -i 44100_s16le_2.pcm -ar 48000 -ac 1 -f f32le 48000_f32le_1.pcm
```

#### 编程
```C++
swr_convert(ctx,
            outAudioData, outNbSamples,
            (const uint8_t **)inAudioData,
            inNbSamples)
```

## AAC编码
pcm转wav
```shell
 ffmpeg -f s16le -ar 44100 -ac 2 -i 44100_s16le_2.pcm 44100_s16le_2.wav
```

pcm转aac
```shell
ffmpeg -ar 44100 -ac 2 -f s16le -i in.pcm -c:a libfdk_aac out.aac
```

wav转aac
```shell
ffmpeg -i in.wav -c:a libfdk_aac out.aac
```

AAC编码的文件扩展名主要有3种：aac、m4a、mp4。
```shell
# m4a

ffmpeg -i in.wav -c:a libfdk_aac out.m4a

# mp4

ffmpeg -i in.wav -c:a libfdk_aac out.mp4
```

编码流程：
![[Pasted image 20230625092349.png]]
1.获取编码器: avcodec_find_encoder_by_name("libfdk_aac")

2.检查PCM格式是否被编码器支持

3.创建编码上下文: AVCodecContext *ctx = avcodec_alloc_context3(codec)

4.给上下文设置参数

5.打开编码器: avcodec_open2

6.创建AVFrame: av_frame_alloc

7.创建AVPacket: av_packet_alloc

8.打开文件

9.读取数据，放入AVFrame

10.把AVFrame数据放入编码器: avcodec_send_frame

11.从编码器中获取编码好的数据并放入AVPacket: avcodec_receive_packet

12.写入文件

13.全部读完以后刷新缓冲区

14.释放资源

